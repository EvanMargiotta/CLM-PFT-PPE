{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ea1567-72a3-4ae1-b765-acbe0afc705b",
   "metadata": {},
   "source": [
    "# 2) Generate Trait Statistics #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd0364-d964-4789-91b6-dc05fe8dfa30",
   "metadata": {},
   "source": [
    "This notebook takes the parameter file used to define the 500 model runs and produces trait statistics at every grid cell.<br>\n",
    "<br>\n",
    "Inputs: <br>\n",
    "Metrics.nc - generated from notebook 1 - contains Cveg used for weighting traits<br>\n",
    "wave1_params.nc - param file detailing the scaler (0-1) used to set traits in each of the 500 model runs<br>\n",
    "PFTperturbation-info.csv - information on the perturbation ranges for each trait<br>\n",
    "PFTparameters-default.csv - trait default values<br>\n",
    "PFTparameters-min.csv - min of trait pertubation range <br>\n",
    "PFTparameters-max.csv - max of trait pertubation range <br>\n",
    "\n",
    "Ouputs:\n",
    "Traits.nc - contains trait parameter values and aggregated grid cell mean, sd, and cv of traits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c1b92-d0ec-49ee-b393-6a8a603de053",
   "metadata": {},
   "source": [
    "## Load in Packages ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "088b3bc9-2738-4280-89fc-95cfda2c8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import importlib.util\n",
    "\n",
    "repo_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eb3da4-dfa9-47f2-bf48-1ae5ec9c5fb4",
   "metadata": {},
   "source": [
    "## Set up functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962317a1-c3ca-48bc-84f5-893df0970f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pftnames = np.asarray(['not_vegetated', \n",
    "                       'needleleaf_evergreen_temperate_tree',\n",
    "                       'needleleaf_evergreen_boreal_tree', \n",
    "                       'needleleaf_deciduous_boreal_tree',\n",
    "                       'broadleaf_evergreen_tropical_tree',\n",
    "                       'broadleaf_evergreen_temperate_tree',\n",
    "                       'broadleaf_deciduous_tropical_tree',\n",
    "                       'broadleaf_deciduous_temperate_tree', \n",
    "                       'broadleaf_deciduous_boreal_tree',\n",
    "                       'broadleaf_evergreen_shrub', \n",
    "                       'broadleaf_deciduous_temperate_shrub',\n",
    "                       'broadleaf_deciduous_boreal_shrub', \n",
    "                       'c3_arctic_grass',\n",
    "                       'c3_non-arctic_grass', \n",
    "                       'c4_grass', \n",
    "                       'c3_crop'], dtype=object)\n",
    "\n",
    "pft_traits = ['froot_leaf',\n",
    "             'kmax',\n",
    "             'krmax',\n",
    "             'leaf_long',\n",
    "             'leafcn',\n",
    "             'lmr_intercept_atkin',\n",
    "             'medlynintercept',\n",
    "             'medlynslope',\n",
    "             'psi50',\n",
    "             'slatop',\n",
    "             'stem_leaf',\n",
    "             'theta_cj']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743b1a0-9ded-42f6-a0be-933b90b982cd",
   "metadata": {},
   "source": [
    "## Load in data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c725a200-3f95-44d3-b8e0-266c2e4697c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics = xr.open_dataset(repo_dir+'/input/Metrics.nc')\n",
    "\n",
    "\n",
    "trait_data = xr.open_dataset(repo_dir+'/params/wave1_params.nc')\n",
    "traits = trait_data['parameter'].values\n",
    "\n",
    "trait_info = pd.read_csv(repo_dir+'/params/PFTperturbation-info.csv')\n",
    "trait_info = trait_info[trait_info['name'].isin(traits)]\n",
    "\n",
    "trait_default = pd.read_csv(repo_dir+'/params/PFTparameters-default.csv')\n",
    "trait_default = trait_default.transpose()\n",
    "trait_default.columns = trait_default.iloc[0]\n",
    "trait_default = trait_default[1:17]\n",
    "trait_default = xr.Dataset.from_dataframe(trait_default).isel(index = slice(1,18)).rename({'index':'pft'})\n",
    "\n",
    "\n",
    "trait_mins = pd.read_csv(repo_dir+'/params/PFTparameters-min.csv')\n",
    "trait_mins = trait_mins.transpose()\n",
    "trait_mins.columns = trait_mins.iloc[0]\n",
    "trait_mins = trait_mins[1:17]\n",
    "trait_mins = xr.Dataset.from_dataframe(trait_mins)\n",
    "\n",
    "\n",
    "trait_maxs = pd.read_csv(repo_dir+'/params/PFTparameters-max.csv')\n",
    "trait_maxs = trait_maxs.transpose()\n",
    "trait_maxs.columns = trait_maxs.iloc[0]\n",
    "trait_maxs = trait_maxs[1:17]\n",
    "trait_maxs = xr.Dataset.from_dataframe(trait_maxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ded896-459d-4657-a54a-44dd7db9a8ff",
   "metadata": {},
   "source": [
    "## Calculate Ecosystem Scale Grid Cell Means and Coefficient of Variations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867d91b1-518f-420f-8f20-442ceee19f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished froot_leaf\n",
      "finished kmax\n",
      "finished krmax\n",
      "finished leaf_long\n",
      "finished leafcn\n",
      "finished lmr_intercept_atkin\n",
      "finished medlynintercept\n",
      "finished medlynslope\n",
      "finished psi50\n",
      "finished slatop\n",
      "finished stem_leaf\n",
      "finished theta_cj\n",
      "finished with 0\n",
      "finished with 100\n",
      "finished with 200\n",
      "finished with 300\n"
     ]
    }
   ],
   "source": [
    "trait_list = []\n",
    "for param in trait_data['parameter'].values:\n",
    "    trait = trait_data.sel(parameter = param)\n",
    "    trait = trait.reset_coords('parameter', drop = True)\n",
    "    trait = trait.rename({'wave1_params':param})\n",
    "    trait_list.append(trait)\n",
    "traitds = xr.merge(trait_list)\n",
    "\n",
    "pft_traits = list(trait_maxs.variables)[list(trait_maxs.variables).index('froot_leaf'):list(trait_maxs.variables).index('theta_cj')+1]\n",
    "\n",
    "traits_norm = traitds[pft_traits].assign_coords({'ens': range(1,501)})\n",
    "for trait in pft_traits:\n",
    "    traits_norm = traits_norm.rename({trait:trait+'_Norm'})\n",
    "\n",
    "mins = []\n",
    "maxs = []\n",
    "for index, row in trait_info.iterrows():\n",
    "    try:\n",
    "        min_val = float(row['min'])\n",
    "        mins.append(min_val)\n",
    "        max_val = float(row['max'])\n",
    "        maxs.append(max_val)\n",
    "    except ValueError:\n",
    "        if 'percent' in str(row['min']):\n",
    "            percent_val_min = float(row['min'][:2])\n",
    "            percent_val_max = float(row['max'][:2])\n",
    "            try:\n",
    "                default_val = float(row['CLM5 Default Value(s)'])\n",
    "                min_val = (1 - percent_val_min/100) * default_val\n",
    "                max_val = (1 + percent_val_max/100) * default_val\n",
    "                mins.append(min_val)\n",
    "                maxs.append(max_val)\n",
    "            except ValueError:\n",
    "                mins.append(float('nan'))\n",
    "                maxs.append(float('nan'))\n",
    "        else:\n",
    "            mins.append(float('nan'))\n",
    "            maxs.append(float('nan'))\n",
    "\n",
    "trait_info['min_adjusted'] = mins\n",
    "trait_info['max_adjusted'] = maxs\n",
    "\n",
    "trait_info = trait_info.dropna(subset=['min_adjusted'])\n",
    "trait_info = trait_info[['name','min_adjusted','max_adjusted']]\n",
    "trait_info = trait_info[trait_info['name'] != 'medlynintercept']\n",
    "\n",
    "# Create a dataset for scaled values\n",
    "trait_values_scaled = xr.Dataset()\n",
    "\n",
    "# Loop through each trait\n",
    "for trait in trait_maxs.data_vars:\n",
    "    # Extract maximum, minimum, and scaling factor for the current trait\n",
    "    max_values = trait_maxs[trait]\n",
    "    min_values = trait_mins[trait]\n",
    "    scale_factors = trait_data.sel(parameter = trait).wave1_params\n",
    "    \n",
    "    # Scale the trait values using the ensemble and pft dimensions\n",
    "    scaled_values = np.asarray(min_values.astype('double')) + scale_factors * (max_values.astype('double').rename({'index':'pft'}) - min_values.astype('double').rename({'index':'pft'}))\n",
    "    \n",
    "    dims = ('ens', 'pft')\n",
    "    coords = {'ens': np.arange(1, 501), 'pft': trait_mins.rename({'index':'pft'}).pft}\n",
    "    \n",
    "    da_scaled = xr.DataArray(scaled_values, dims=dims, coords = coords)\n",
    "    trait_values_scaled[trait] = da_scaled\n",
    "    \n",
    "    print(f'finished {trait}')\n",
    "\n",
    "\n",
    "trait_values_scaled = xr.merge([trait_values_scaled])\n",
    "\n",
    "universal_params = []\n",
    "for index, row in trait_info.iterrows():\n",
    "    params = []\n",
    "    for i in range(0,500):\n",
    "        trait = row['name']\n",
    "        trait_scalers = trait_data.sel(ens = i, parameter = trait).mean(dim = 'pft').wave1_params.item()\n",
    "        scaled_values = row['min_adjusted'] + trait_scalers * (row['max_adjusted'] - row['min_adjusted'])\n",
    "        params.append(scaled_values)\n",
    "    trait_dataarray = xr.DataArray(params, dims=['ens'], name=trait)\n",
    "    universal_params.append(trait_dataarray)\n",
    "universal_params = xr.merge(universal_params).drop('theta_cj')\n",
    "\n",
    "all_traits  = xr.merge([Metrics.TOTVEGC, trait_values_scaled, universal_params, traits_norm])\n",
    "all_traits = all_traits.drop_sel(pft = 'c3_crop')\n",
    "\n",
    "gcds = []\n",
    "for i in all_traits.gridcell.values:\n",
    "    ds = all_traits.sel(gridcell = i)\n",
    "    weights = ds.TOTVEGC.mean(dim = 'ens') / ds.TOTVEGC.sum(dim = 'pft').mean(dim = 'ens')\n",
    "    tds = xr.Dataset()\n",
    "    for t in pft_traits:\n",
    "        weighted_mean = (weights * ds[t]).sum(dim='pft')\n",
    "        tds[t + 'Mean'] = weighted_mean\n",
    "        \n",
    "        try:\n",
    "            weighted_variance = (weights * (ds[t] - weighted_mean) ** 2).sum(dim='pft') / weights.sum(dim='pft')\n",
    "            weighted_std_dev = np.sqrt(weighted_variance.astype('float64'))\n",
    "            weighted_cv = weighted_std_dev/weighted_mean\n",
    "        except:\n",
    "            weighted_std_dev = np.nan\n",
    "            weighted_cv = np.nan\n",
    "            \n",
    "        tds[t + 'SD'] = weighted_std_dev\n",
    "        tds[t + 'CV'] = weighted_cv\n",
    "    gcds.append(tds)\n",
    "    if i % 100 == 0:\n",
    "        print(f'finished with {i}')\n",
    "tds = xr.concat(gcds, dim = 'gridcell')\n",
    "\n",
    "traitsds_final = xr.merge([all_traits, tds])\n",
    "traitsds_final = traitsds_final.drop_vars('TOTVEGC').mean(dim = 'time')\n",
    "traitsds_final.attrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ccfc61-85e2-472f-9b7b-afcc2b9cc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "traitsds_final.to_netcdf(repo_dir+'/input/Traits.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AridityEnv]",
   "language": "python",
   "name": "conda-env-AridityEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
